# ETL Project with Azure Databricks

## Overview
This project involves Extract, Transform, Load (ETL) processes using Azure Databricks. The data is sourced from a CSV file provided by Microsoft, and transformations are performed using Python within a Databricks notebook.

## Setup
Azure Databricks Workspace:

Create an Azure Databricks workspace in the Azure portal.
Set up necessary configurations, including networking and encryption.
Databricks Notebook:

Create a new notebook in Databricks (e.g., ETL_Notebook).
CSV File:

Download the CSV file ("Import_User_Sample_en.csv") from Microsoft.
Upload the CSV file to a public GitHub repository.

## Transformation Details
Extract Numeric Information:

Extracted numeric information from the 'Office Phone' and 'Mobile Phone' columns.
Create a New Column (Phone Type):

Created a new column 'Phone Type' based on the presence of information in 'Office Phone' and 'Mobile Phone'.
## Notes
Ensure that the Azure Databricks workspace is properly set up with the required configurations.
Make sure the CSV file is publicly accessible on GitHub.


screenshot: 
![Screenshot from 2023-12-06 10-16-21](https://github.com/cleverguns/ETL-Databirkcs-code/assets/41587193/6b30a407-c5f6-47a9-8a88-9ff8aabd4e41)

